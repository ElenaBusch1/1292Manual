\documentclass[letterpaper, 12pt]{book}

\usepackage[pdftex]{graphicx}
\usepackage{epstopdf}
\DeclareGraphicsRule{*}{mps}{*}{}

\usepackage[titletoc]{appendix}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{listings}
\usepackage{float}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{fancyheadings}
\usepackage{titlesec}
\usepackage{multicol}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{tocloft}
\usepackage{tikz}
\usepackage{engord}
\usepackage{comment}
\usetikzlibrary{positioning}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{patterns}
\usetikzlibrary{shapes}
\usetikzlibrary{shapes.geometric}
%\usepackage{fullpage}
\usepackage[left=1in, top=1.2in, right=1in, bottom=1.2in, bindingoffset=0.4in]{geometry}


% Different font in captions
\newcommand{\captionfonts}{\small}

\makeatletter  % Allow the use of @ in command names
\long\def\@makecaption#1#2{%
  \vskip\abovecaptionskip
  \sbox\@tempboxa{{\captionfonts #1: #2}}%
  \ifdim \wd\@tempboxa >\hsize
    {\captionfonts #1: #2\par}
  \else
    \hbox to\hsize{\hfil\box\@tempboxa\hfil}%
  \fi
  \vskip\belowcaptionskip}
\makeatother   % Cancel the effect of \makeatletter

\linespread{1.05}

\renewcommand*\thesection{\arabic{section}}
\renewcommand*\thefigure{\arabic{figure}}
\renewcommand*\theequation{\arabic{equation}}

\setlength{\cftchapnumwidth}{1.2cm}
\renewcommand{\cftchappresnum}{2-}

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{0}
\setcounter{chapter}{-1}

\pagestyle{fancy}
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection.#1}{}}

\newcommand{\myskip}{\vspace{0.5\baselineskip}}

\lhead[\rightmark]{Experiment 2-\thechapter}
\cfoot{\thepage}
\rhead[Experiment 2-\thechapter]{\leftmark}

%\fancypagestyle{plain}{
    %\fancyhf{}
    %\renewcommand{\headrulewidth}{0pt}
    %\renewcommand{\footrulewidth}{0pt}
%}


\begin{document}

\pagestyle{empty}
\include{cover}
\newpage
\phantom{aaa}
\clearpage
\tableofcontents
\addtocontents{toc}{\protect\thispagestyle{empty}}
\cleardoublepage

\pagestyle{fancy}

\titlespacing*{\chapter}{0pt}{-50pt}{20pt}
\titleformat{\chapter}[display]
    {\bfseries\huge\filcenter}
    {\underline{Introduction 2-\thechapter}}
    {0pt}
    {\huge}

\setcounter{page}{1}
\include{intro}

\titleformat{\chapter}[display]
    {\bfseries\huge\filcenter}
    {\underline{Experiment 2-\thechapter}}
    {0pt}
    {\huge}

%\include{Exp1/ElectricFields}
\include{Exp2/DCCircuits} %DC circuits - Very old, need lots of work and images
%\include{Exp3/Capacitance}
%\include{Exp4/TheMagneticField}
%\include{Exp5/emOfTheElectron}
%\include{Exp6/GeometricalOpticsI_Intro}
% \include{Exp7/Optical_Instruments} %Optics2 - Totally restored
% \include{Exp8/PolarizationAndInterference} %not done - Images Restored
%\include{Exp9/TheSpectrumOfTheHydrogenAtom}
%\include{Exp10/AbsorptionOfBetaAndGammaRays}

\titleformat{\chapter}[display]
    {\bfseries\huge\filright}
    {\underline{Appendix \thechapter}}
    {0pt}
    {\huge}

\appendix
\appendixpage
\addappheadtotoc

\lhead[\rightmark]{Appendix 2-\thechapter}
\cfoot{\thepage}
\rhead[Appendx 2-\thechapter]{\leftmark}

\chapter{Review of Error Analysis}

\section{Types of Uncertainties}

Uncertainty in a measurement can arise from three possible origins: the measuring device, the procedure of how you measure, and the observed quantity itself. Usually the largest of these will determine the uncertainty in your data. \myskip

Uncertainties can be divided into two different types: systematic uncertainties and random (statistical) uncertainties\footnote{If you were to engage in further research, random uncertainty is typically referred to as statistical uncertainty.}.

\subsection{Systematic Uncertainties}


Systematic uncertainties or systematic errors always bias results in one specific direction. They will cause your measurement to consistently be higher or lower than the accepted value. \myskip

An \emph{example} of a systematic error follows. Assume you want to measure the length of a table in cm using a meter stick. However, the stick is made of metal that has contracted due to the temperature in the room, so that it is less than one meter long. Therefore, all the intervals on the stick are smaller than they should be. Your numerical value for the length of the table will then always be larger than its actual length no matter how often or how carefully you measure. Another example might be measuring temperature using a mercury thermometer in which a bubble is present in the mercury column. \myskip

Systematic errors are usually due to imperfections in the equipment, improper or biased observation, or the presence of additional physical effects not taken into account. (An example might be an experiment on forces and acceleration in which there is friction in the setup and it is not taken into account!) \myskip

In performing experiments, try to estimate the effects of as many systematic errors as you can, and then remove or correct for the most important. By being aware of the sources of systematic error beforehand, it is often possible to perform experiments with sufficient care to compensate for weaknesses in the equipment.

\subsection{Random Uncertainties}

In contrast to systematic uncertainties, random uncertainties are an unavoidable result of measurement, no matter how well designed and calibrated the tools you are using. Whenever more than one measurement is taken, the values obtained will not be equal but will exhibit a spread around a mean value, which is considered the most reliable measurement. That spread is known as the random uncertainty. Random uncertainties are unbiased -- meaning it is equally likely that an individual measurement is too high or too low. \myskip

From your everyday experience you might be thinking, ``Stop! Whenever I measure the length of a table with a meter stick I get exactly the same value no matter how often I measure it!''   This may happen if your meter stick is insensitive to random measurements, because you use a coarse scale (like $\mathrm{mm}$) and you always read the length to the nearest $\mathrm{mm}$. But if you would use a meter stick with a finer scale, or if you interpolate to fractions of a millimeter, you would definitely see the spread. As a general rule, if you do not get a spread in values, you can improve your measurements by using a finer scale or by interpolating between the finest scale marks on the ruler. \myskip

How can one reduce the effect of random uncertainties?  Consider the following \emph{example}. Ten people measure the time of a sprinter using stopwatches. It is very unlikely that each of the ten stopwatches will show exactly the same result. Even if all of the people started their watches at exactly the same time (unlikely) some of the people will have stopped the watch early, and others may have done so late. You will observe a spread in the results. If you \emph{average} the times obtained by all ten stop watches, the \emph{mean} value will be a better estimate of the true value than any individual measurement, since the uncertainty we are describing is random, the effects of the people who stop early will compensate for those who stop late. In general, making multiple measurements and averaging can reduce the effect of random uncertainty. \myskip

\emph{Remark}: We usually specify any measurement by including an estimate of the random uncertainty. (Since the random uncertainty is unbiased we note it with a $\pm$ sign). So if we measure a time of 7.6 seconds, but we expect a spread of about 0.2 seconds, we write as a result:
\begin{equation}
    t = (7.6\pm 0.2)\,\mathrm{s}
\end{equation}
indicating that the uncertainty of this measurement is $0.2\,\mathrm{s}$ or about $3\%$. \myskip
\section{Accuracy and Precision}
An important distinction in physics is the difference between the {\it{accuracy}} and the {\it{precision }} of a measurement.
Accuracy refers to the closeness of a measured value to a standard or known value. For example, if in lab you obtain a weight measurement of 3.2 kg for a given substance, but the actual or known weight is 10 kg, then your measurement is not accurate. In this case, your measurement is not close to the known value. \myskip

Precision refers to the closeness of two or more measurements to each other. Using the example above, if you weigh a given substance five times, and get 3.2 kg each time, then your measurement is very precise. Precision is independent of accuracy. You can be very precise but inaccurate, as described above. You can also be accurate but imprecise. \myskip

For example, if on average, your measurements for a given substance are close to the known value, but the measurements are far from each other, then you have accuracy without precision. \myskip

A good analogy for understanding accuracy and precision is to imagine a basketball player shooting baskets. If the player shoots with accuracy, his aim will always take the ball close to or into the basket. If the player shoots with precision, his aim will always take the ball to the same location which may or may not be close to the basket. A good player will be both accurate and precise by shooting the ball the same way each time and each time making it in the basket.
\section{Numerical Estimates of Uncertainties}

For this laboratory, we will estimate uncertainties with three approximation techniques, which we describe below. You should note which technique you are using in a particular experiment.

\subsection{Upper Bound}

Most of our measuring devices in this lab have scales that are coarser than the ability of our eyes to measure.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.5\textwidth]{./pic/image1.png}
    \end{center}
    \caption{Measuring Length}
    \label{fig:measure}
\end{figure}

For example in the figure above, where we are measuring the length of an object against a meter stick marked in cm, we can definitely say that our result is somewhere between $46.4\,\mathrm{cm}$ and $46.6\,\mathrm{cm}$. We assume as an \emph{upper} bound of our uncertainty, an amount equal to \emph{half} this width (in this case $0.1\,\mathrm{cm}$). The final result can be written as:
\begin{equation}
    \ell = (46.5\pm 0.1)\,\mathrm{cm}
\end{equation}

There will be many circumstances when the error is more complicated than simply the coarseness of the measuring tool. For example, if you find yourself measuring something that is very long or hard to line up properly with a meter stick. In this case, you may need to use some judgement of the best possible measurement to make and the uncertainty will be greater than the millimeter precision of your meter stick. \textbf{It is always best to slightly overestimate error and allow yourself some wiggle room if you feel that better represents your measurement!}

\subsection{Estimation from the Spread (2/3 method)} \label{ssec:twothirds}

For data in which there is random uncertainty, we usually observe individual measurements to cluster around the mean and drop in frequency as the values get further from the mean (in both directions).\footnote{There is a precise mathematical procedure to obtain uncertainties (standard deviations) from a number of measured values. Here we will apply a simple ``rule of thumb'' that avoids the more complicated mathematics of that technique. The uncertainty using the standard deviation for the group of values in our example below is 0.2.}  Find the interval around the mean that contains about 2/3 of the measured points: \emph{half} the size of this interval is a good estimate of the uncertainty in each measurement. \myskip

The reasons for choosing a range that includes 2/3 of the values come from the underlying statistics of the normal (or Gaussian) distribution (see figure \ref{fig:bellcurve}). This choice allows us to accurately add and multiply values with errors and has the advantage that the range is not affected much by outliers and occasional mistakes. A range that always includes all of the values is generally less meaningful. \myskip

\emph{Example}: You measure the following values of a specific quantity:
\begin{equation*}
    9.7,\:9.8,\:10,\:10.1,\:10.1,\:10.3
\end{equation*}
The mean of these six values is 10.0. The interval from 9.8 to 10.1 includes 4 of the 6 values; we therefore estimate the uncertainty to be 0.15. The result is that the best estimate of the quantity is 10.0 and the uncertainty of a single measurement is 0.2.\footnote{Note that about 5\% of the measured values will lie \emph{outside} $\pm$ twice the uncertainty}\footnote{While the above method for calculating uncertainty is good enough for our purposes, it oversimplifies a bit the task of calculating the uncertainty of the \emph{mean} of a quantity.  For those who are interested, please see the appendix for elaboration and clarification. }

\subsection{Square-Root Estimation in Counting}

For inherently random phenomena that involve counting individual events or occurrences, we measure only a single number $N$. This kind of measurement is relevant to counting the number of radioactive decays in a specific time interval from a sample of material, for example. It is also relevant to counting the number of left-handed people in a random sample of the population. The (absolute) uncertainty of such a single measurement, $N$, is estimated as the square root of $N$ (a counting measurement is expressed as $N \pm \sqrt{N}$). As an example, if we measure 50 radioactive decays in 1 second we should present the result as $50\pm 7$ decays per second. (The quoted uncertainty indicates that a subsequent measurement performed identically could easily result in numbers differing by 7 from 50.)

\section{Relative and Absolute Uncertainty}

There are two ways to record uncertainties: the absolute value of the uncertainty or the uncertainty relative to the mean value. So in the example above, you can write $c = (5.1 \pm 0.3)\,\mathrm{cm}$ or equally well $c = 5.1\,\mathrm{cm}\; (1.00 \pm 0.06)$. You can see that if you multiply out the second form you will obtain the first, since $5.1 \times 0.06 = 0.3$. The second form may look a bit odd, but it tells you immediately that the uncertainty is 6\% of the measured value. The number $0.3\,\mathrm{cm}$ is the absolute uncertainty and has the same units as the mean value (cm). The 0.06 (or 6\%) is the relative uncertainty and has no units since it is the ratio of two lengths. It's important to use proper notation when describing uncertainty to remove any unwanted ambiguity, so make sure it's clear when you are using relative or absolute errors.

\section{Propagation of Uncertainties}

Often, we are not directly interested in a measured value, but we want to use it in a formula to calculate another quantity. In many cases, we measure many of the quantities in the formula and each has an associated uncertainty. We deal here with how to propagate uncertainties to obtain a well-defined uncertainty on a computed quantity.

\subsection{Adding/Subtracting Quantities}

When we \textbf{add or subtract} quantities, the combined uncertainty is the \textbf{sum of the absolute uncertainties} of the constituent parts\footnote{The propagation of random uncertainties is actually slightly more complicated, but the procedure outlined here usually represents a good approximation, and it never underestimates the uncertainty. See the appendix for more information.}.

Take as an example measuring the length of a dog. We measure the distance between the left wall and the tail of the dog and subtract the distance from the wall to the dog's nose.
\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.5\textwidth]{./pic/image2.png}
    \end{center}
    \caption{Measuring a Dog}
    \label{fig:dog}
\end{figure}
So the total length of the dog is:
\begin{equation}
    \begin{split}
        \text{Length} &= (1.53\pm 0.05)\,\mathrm{m} - (0.76 \pm 0.02)\,\mathrm{m} \\
        &= \left( 1.53 - 0.76 \right)\pm\left( 0.05 + 0.02 \right)\,\mathrm{m} \\
        &= \left( 0.77 \pm 0.07 \right)\,\mathrm{m}
    \end{split}
\end{equation}

\subsection{Multiplying/Dividing Quantities}

When we \textbf{multiply or divide} quantities, the combined \textbf{relative} uncertainty is the \textbf{sum of the relative uncertainties} of the constituent parts.\footnote{Our calculation of the uncertainty actually overestimates it. The correct method does not add the absolute/relative uncertainty, but rather involves evaluating the square root of the sum of the squares. For more information please refer to the appendix of this lab manual.}

Take as an example the area of a rectangle, whose individual sides are measured to be:
\begin{align}
    a = 25.0\pm 0.5\,\mathrm{cm} = 25.0\,\mathrm{cm}\;(1.00\pm 0.02) \nonumber \\
    b = 10.0\pm 0.3\,\mathrm{cm} = 10.0\,\mathrm{cm}\;(1.00\pm 0.03)
\end{align}

The area is obtained as follows:
\begin{equation}
    \begin{split}
        \text{Area} &= \left( 25.0\pm 0.5\,\mathrm{cm} \right)\cdot\left( 10.0\pm 0.3\,\mathrm{cm} \right) \\
        &= 25.0\,\mathrm{cm}\;\left( 1.00\pm 0.02 \right)\cdot 10.0\,\mathrm{cm}\;\left( 1.00\pm 0.03 \right) \\
        &= \left( 25.0\,\mathrm{cm}\cdot 10.0\,\mathrm{cm} \right)\left( 1.00\pm \left( 0.02 + 0.03 \right) \right) \\
        &= 250.0\,\mathrm{cm}^2\;(1.00 \pm 0.05) \\
        &= 250.0\pm 12.5\,\mathrm{cm}^2 \\
        &= 250 \pm 10\,\mathrm{cm}^2
    \end{split}
\end{equation}

Note that the final step has rounded both the result and the uncertainty to an appropriate number of significant digits, given the uncertainty on the lengths of the sides. \myskip

\underline{Remarks:} Note that uncertainties on quantities used in a mathematical relationship always increase the uncertainty on the result. The quantity with the biggest uncertainty usually dominates the final result. Often one quantity will have a much bigger uncertainty than all the others. In such cases, we can simply use this main contribution.

\subsection{Multiplication by a Constant}

Multiplying a value by a constant leaves the relative error unchanged. This is equivalent to multiplying the absolute error by the same constant. For example, suppose we are trying to find the circumference of a circle knowing it's radius as $r=1.0 \pm 0.1 \hspace{1mm} \text{cm}$ with error; we would calculate the circumference with error as follows.

\begin{gather}
C = 2\pi r \nonumber \\
 C= 2\pi (1.0 \pm 0.1) \\
 C=6.3 \pm 0.6 \hspace{1mm}  \text{cm} \nonumber
\end{gather}

\subsection{Powers and Roots}

When raising a value to a certain power, its \textbf{relative uncertainty is multiplied by the exponent}. This applies to roots as well, since taking the root of a number is equivalent to raising that number to a fractional power.\myskip

Squaring a quantity involves multiplying its relative uncertainty by 2, while cubing a quantity causes its relative uncertainty to be multiplied by 3.\myskip

Taking the square root of a quantity (which is equivalent to raising the quantity to the 1/2 power) causes its relative uncertainty to be multiplied by 1/2. For example, if you know the area of a square to be:
\begin{equation}
    \text{Area} = 100\pm 8\,\mathrm{m^2} = 100\,\mathrm{m}^2\;(1.00\pm 0.08)
\end{equation}
then it follows that the side of the square is:
\begin{equation}
    \text{Side} = 10\,\mathrm{m}\;\left( 1.00\pm 0.04 \right) = 10.0\pm 0.4\,\mathrm{m}
\end{equation}
The most general rule for finding the error in powers and roots is mathematically represented as follows.
\begin{gather}
f(x) = x^n \\
\frac{\sigma_{f(x)}}{f(x)} = |n| \frac{\sigma_x}{x}
\end{gather}
Where $\sigma$ is the {\it{absolute}} uncertainty and $f(x)$ is some power or root of $x$.

\subsection{Other Functions}

If you need to calculate the error of a calculation that does not fit into one of these rules (such as trigonometric functions or logarithmic ones), here is a manual method that you can use.\myskip

Based upon the error of the quantity that you determined, you can find the maximum and minimum values of the quantity that you are calculating. The value that you found should be roughly midway between these two quantities. Then if you split the difference between the maximum and minimum you should obtain a reasonable estimate of the error. Mathematically, you would do so as follows.
\begin{gather}
\sigma_{f(x)} = \frac{f(x + \sigma_x) - f(x - \sigma_x)}{2}
\end{gather}

Here is an example: Suppose you measure an angle to be $(47.3 \pm 0.5)^\circ$ and you want to determine the error of $\sin(47.3 \pm 0.5)^\circ$. You find that $\sin(47.3) = 0.735$. Based upon your reported uncertainty, you know that your angle could be as large as $47.8^\circ$ and as small as $46.8^\circ$, and therefore you should calculate $\sin(47.8) = 0.741$ and $\sin(46.8) = 0.729$. So your calculated value is 0.735 but it can be as low as 0.729 and as high as 0.741 and therefore, if you halve the difference between 0.729 and 0.741 you get a reasonable error estimate of 0.006. So you should report your value as $0.735 \pm 0.006$.

\section{Best-Fit Line}

In most research laboratories, plotting measurements is found to be the preferred method of reviewing the data and quantitatively measuring the relationship between the experimental variables. This is effective because we often have some idea of the expected relationship between the variables {\it{a priori}}. In these labs, this expected relationship is almost always arranged to be a straight line. But even if we know that the ideal points fit on a precise straight line, experimentally measured data points will not always lie on a single line -- because the measurements always have intrinsic uncertainty. Therefore when the points are plotted, we should include error bars on both axes to indicate the uncertainties in the data. Because real measurements do not all lie on a single straight line, there are a variety of possible lines you might choose to fit the data. \myskip

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.9\textwidth, height=0.5\textwidth]{./pic/image13.jpg}
    \end{center}
    \caption{Left: an example best-fit line. Right: the maximum and minimum possible slope from our data used to calculate uncertainty in the best-fit line. Notice how we have drawn the lines on the outer bounds of the error bars to achieve the maximum and minimum possible slope within the error bars.}
    \label{fig:bestfit}
\end{figure}

How do we know which line represents the best fit? There is an exact mathematical procedure to obtain the best-fit line, but this is usually a very tedious calculation which is outside the scope of this lab. For experiments in this course, you will be using Excel's built-in fitting function for data. The process for doing which will be explained in your next lab. However, if you are interested in learning how to approximate the technique without a computer, please see the appendix.\myskip

\underline{Remark}: Often in our experiments the data points will not look as nice as in the above examples. One or several points may not be close to any best-fit line you try. Such anomalous points may occur, for example, because of a mistake in measuring. In such cases, it is acceptable to ignore these anomalies when estimating the best-fit line (and of course you must note this fact down in your lab report).  Dropping anomalous points must be done with extreme care and only rarely (if you know the point is not physically meaningful).\footnote{More than once, data points that did not behave as theory predicted turned out to be new effects and led to Nobel prizes!}  It is better to choose a line with as many points above the line as below. If you are not sure of your measurements, it is better to re-measure or to take more data points. \myskip

\section{Numerical Statistics}
The previous discussions of uncertainty and error tell us how we can quantitatively describe our inability to make perfect single measurements. However, in real physics experiments, very rarely do we draw conclusions from a single data points. As such, it is essential that we know how to quantify error in sets of data. The 2/3 methods as discussed in Section \ref{ssec:twothirds} provides a good estimation of data statistics, but we can more rigorously calculate data set statistics. In statistics, a data set can be well described by the following four fundamental quantities: mean, median, mode, and standard deviation. The mean of a data set is the sum of all numbers in the data set divided by the number of points in the set. It is defined in the following manner.
\begin{gather}
 \text{Average} \equiv \bar x= \sum_{i} \frac{x_i}{N}
\end{gather}
The median of a data set is the middle value in a set of numbers listed in increasing order. The mode is the number that occurs the most number of times in the data set. The standard deviation describes  how the numbers in the data set are distributed around the mean. It is defined as follows.
\begin{gather}
\text{standard deviation} \equiv \sigma = \sqrt{\sum_i \frac{(x_i - \bar x)^2}{N}}
\end{gather}

These four statistical quantities give us enough information to characterize the distribution of our data set. For example, let's consider the two following Data Sets.
\myskip
\begin{center}
\begin{tabular}{c | c | c | c | c | c | c | c | c | c | c | c | c | c  }
&&&&&&&&&&Mean&Median&Mode& $\sigma$ \\
Set 1 & 9&8&11&13&10&10&12&6&9 &9.8&10&10&2.2\\
Set 2 & 11&0&10&40&2&3&10&10&4 &9.8&10&10&11.4
\end{tabular}
\end{center}
\myskip
Notice how both Data Sets have the same mean, median, and mode, which tells us the data points in each set are centered on the mean value of $9.8$. However, the standard deviations are quite different. The large standard deviation in Data Set 2 tells us there must be outliers in the data set which increase the distribution. Whereas, the relatively small standard deviation in the first data set tells us the numbers in set 1 are clustered closely together. Standard deviation is especially important because  it tells us exactly how distributed the number are around the mean value, which gives an indication of how error affects the spread of data points (for example, see figure \ref{fig:bellcurve} for the canonical "bell curve" distribution, also known as the gaussian distribution). The 2/3 method as discussed in Section \ref{ssec:twothirds} is an approximation to the standard deviation since $2/3 \sim 66\%$, which roughly corresponds to the first standard deviation (see figure \ref{fig:bellcurve}).

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.7\textwidth]{./pic/image3.png}
    \end{center}
    \caption{An example of a Gaussian distribution, also known as a bell curve. $\sim 68\%$ of the data points are within 1 standard deviation, $\sim 95\%$ of that data points are contained within 2 standard deviations, $\sim 99.5 \%$ of the data points are contained within 3 standard deviations, etc...}
    \label{fig:bellcurve}
\end{figure}

\section{Number of Significant Digits}

The number of significant digits in a result refers to the number of digits that are relevant. The digits may occur after a string of zeroes. For example, the measurement of $2.3\,\mathrm{mm}$ has two significant digits. This does not change if you express the result in meters as $0.0023\,\mathrm{m}$. The number 100.10, by contrast, has 5 significant digits\footnote{Another way to find the number of significant digits is to convert to scientific notation, and count the number of digits in the mantissa (also significand or coefficient). For example: for $1.2\times 10^{2}$, there are two significant digits in $1.2$. }.

When you record a result, you should use the calculated error to determine how many significant digits to keep. Let's illustrate the procedure with the following example. Assume you measure the diameter of a circle to be $d = 1.6232\,\mathrm{cm}$, with an uncertainty of $0.102\,\mathrm{cm}$. You now round your uncertainty to one or two significant digits (up to you). So (using one significant digit) we initially quote $d = (1.6232 \pm 0.1)\,\mathrm{cm}$. Now we compare the mean value with the uncertainty, and keep only those digits that the uncertainty indicates are relevant. Finally, we quote the result as $d = (1.6 \pm 0.1)\,\mathrm{cm}$ for our measurement.

Suppose further that we wish to use this measurement to calculate the circumference $c$ of the circle with the relation $c = \pi\cdot d$. If we use a standard calculator, we might get a 10 digit display indicating:
\begin{equation}
    c = 5.099433195\pm 0.3204424507\,\mathrm{cm}
\end{equation}
This is not a reasonable way to write the result!  The uncertainty in the diameter had only one significant digit, so the uncertainty of the circumference calculated from the diameter cannot be substantially better. Therefore we should record the final result as:
\begin{equation}
    c = 5.1\pm 0.3\,\mathrm{cm}
\end{equation}
(If you do intermediate calculations, it is a good idea to keep as many figures as your calculator can store. The above argument applies when you \underline{record} your results!)


\chapter{Error Analysis With Excel}

\section{Plotting with Excel}
An important set of data analysis tools in Excel are plotting and linear fit functions. You will need to plot and fit data many times throughout this lab course, so make sure you are familiar with this section. Below is a walkthrough of plotting and fitting a set of data with error in excel.
\begin{enumerate}
\item Before plotting, you need to have 4 columns with data: x data, y data, x error data, and y error data. Make sure you have entered the information into excel.
\item First select your x data and y data (you can select multiple boxes in excel by holding down the ctrl button while selecting). Make sure to select your x data first or your x and y axes will be switched.
\item Choose the subheading ``insert", then ``Scatter", then ``Scatter with straight lines and markers". Now your x and y data should be plotted without error bars (see figure \ref{fig:excel1}).

\begin{figure}[h!]
\centering
\includegraphics[height=0.4\textheight, width=0.7\textwidth]{./pic/image4.png}
\caption{Selecting x and y data and creating a lined scatter plot in excel.}
\label{fig:excel1}
\end{figure}

\item To include error bars select your chart, then click the ``plus" marker on the top right of the chart. Check the box titled ``error bars". Now some basic error bars should appear on the plot. These are not based on the error bar data in your excel document, they are standard error bars.
\item To change them so they match your error bar data, select the x axis error bars on your chart, and format the error bars by clicking the ``Custom" selection, then ``specify value".
\item It should now prompt you for positive error values and negative error values. Delete ``$\{1\}$" from the two boxes, and select your error bars using the cursor. Your chart will now have the correct error bars (see figure \ref{fig:excel2}).

\item Repeat steps 5-6 for your y data.
\item To linear fit your data, right click on your data in the plot and select ``Add Trendline". Check the ``Linear", ``Display Equation on chart", and ``Display R-square value on chart" boxes.
\item Now the slope, intercept, and R squared values will be displayed on your chart. R squared is a measure of how well the line fits your data. It should be close to $1$ and at the very least greater than $0.9$.
\end{enumerate}

\begin{figure}[h!]
\centering
\includegraphics[height=0.4\textheight, width=0.7\textwidth]{./pic/image5.png}
\caption{Using your own data set to create x and y error bars in excel.}
\label{fig:excel2}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[height=0.4\textheight, width = 0.7\textwidth]{./pic/image6.png}
\caption{Using excel to perform a linear fit and return the intercept and slope.}
\label{fig:excel3}
\end{figure}

\section{Finding Error in Slope}
\label{sec:linest}

The previous steps will help plot your data, but in order to draw conclusions, you must add uncertainty. Excel has a built in function called LINEST which finds the standard error for a linear fit. Using the same columns of data from before, the walkthrough below will help you calculate the error so you can propagate it further in the experiment.

\begin{enumerate}
\item The LINEST function is an array-type function, meaning it will output more than one number. Start, by highlighting a 2-by-3 section of empty cells (two columns, three rows).
\item With these six cells highlighted, in the input box at the top of the screen type ``= LINEST(" and add the proper arguments. The arguments should be the list of y-values, the list of x-values, TRUE, and TRUE.
For example:
$=\texttt{LINEST}(\texttt{C2:C11, A2:A11, TRUE, TRUE})$.

\item Press CONTROL+SHIFT+ENTER. \it{Note that on a Mac, this is CMD+SHIFT+ENTER.}
\end{enumerate}

Your results should have filled in that 2-by-3 section in the following way:
\begin {table}[H]
\begin{center}
\begin{tabular}{ |c | c | c |}
\hline
Slope &X Intercept \\ \hline
Error of Slope &Error of Intercept \\ \hline
$R^2$ &Error in Y \\ \hline
\end{tabular}
\caption{LINEST function output in Excel.}
\end{center}
\end{table}

\section{Helpful Commands}

Your TA will guide you through the relevant excel commands necessary for data analysis, however a list of some relevant excel commands are listed below. A list of all excel commands can be found on the \href{https://support.office.com/en-us/article/Excel-functions-alphabetical-b3944572-255d-4efb-bb96-c6d90033e188}{Microsoft Office website}\footnote{https://support.office.com/en-us/article/Excel-functions-alphabetical-b3944572-255d-4efb-bb96-c6d90033e188}

\begin{center}
\begin{tabular}{c | c}
\texttt{ABS} & Returns the absolute value of a number \\
\texttt{AVERAGE} & Computes the average of the selected data set \\
\texttt{COS} & Calculates cosine of a number\\
\texttt{DEGREES} & Converts radians to degrees \\
\texttt{EXP} & Returns e raised to the power of a given number \\
\texttt{LN} & Returns the natural logarithm of a number \\
\texttt{MEDIAN} & Finds the median of a data set \\
\texttt{MODE.SNGL} & Finds the most commonly occurring number in a data set\\
\texttt{PI} & Returns the value of pi\\
\texttt{POWER} & Returns the result of a number raised to a power\\
\texttt{SIN} & Calculates the sine of a number\\
\texttt{SQRT} & Calculates the square root of a number\\
\texttt{STDEV.P} & Calculates the standard deviation based on the entire population \\
\texttt{STDEV.S} & Estimates the standard deviation based on a sample \\
\texttt{SUM} & Calculates the sum of a data set\\
\texttt{TAN} & Calculates the tangent of a number
\end{tabular}
\end{center}


\chapter{Advanced Error Analysis}
\section{Clarification of 2/3 Rule}

To find the true uncertainty, we are really interested in the \emph{standard error of the mean}, i.e., how likely it would be for a newly measured average value to be close to our original value were we to perform the experiment again.  The proper way to figure this out would be to get say a thousand friends to perform this experiment in the same way, each using the same number of data points, and then compare the results of everyone.  Each student would calculate his or her own mean, and they would likely all be clustered around some central average.  We could then examine the spread of this cluster of means using the 2/3 rule, and we'd have a quantitative measure of the uncertainty surrounding any single student's measurement.\myskip

While it's usually impractical to get 1000 friends together to repeat an experiment a thousand times, it turns out that the uncertainty (or ``standard error'') of the mean can be estimated with the following formula:
\begin{equation}
    \text{Standard Error Of The Mean} = \frac{\text{Uncertainty Of Single Measurement}}{\sqrt{N}}
\end{equation}
where ``$N$'' is the number of data points in your sample, and ``Uncertainty Of Single Measurement'' is the uncertainty calculated via the 2/3 method.  The ``$\sqrt{N}$'' term should make sense qualitatively -- as we take more and more data points, our measured average becomes less and less uncertain as we approach what should be the ``global'' mean.

\section{The ``Correct'' Way to Add Uncertainties}

The rules we've given for propagating uncertainties through a calculation are essentially correct, and intuitively make sense.  When adding two quantities together, if one has an uncertainty of $\Delta$x and another has an uncertainty of $\Delta y$, the sum could indeed range from $(x+y) - (\Delta x +  \Delta y)$ to $(x+y) + (\Delta x + \Delta y)$.  This implies that the proper way to find the uncertainty of $(x+y)$ is to add their respective absolute uncertainties. \myskip

There is, however, a small problem -- this overestimates the uncertainty!  Since $x$ and $y$ are equally likely to be wrong by either a \emph{positive} amount or a \emph{negative} amount, there's a good chance that the respective errors of each variable will partly cancel one another out.  To account for this, a more accurate way to estimate uncertainty turns out to be to add uncertainties \emph{in quadrature}.  This means:\myskip

\textbf{Adding/Subtracting Quantities}

\begin{equation}
    (A\pm\Delta A) + (B\pm\Delta B) = (A+B)\pm\sqrt{(\Delta A)^2+(\Delta B)^2}
\end{equation}

\myskip\textbf{Multiplying/Dividing Quantities}

\begin{equation}
    A\left(1\pm\frac{\Delta A}{A}\right) \times B\left(1\pm\frac{\Delta B}{B}\right) = \left(A \times B\right) \left ( 1 \pm\sqrt{\left(\frac{\Delta A}{A}\right)^2+\left(\frac{\Delta B}{B}\right)^2} \right )
\end{equation}

While this method gives a closer approximation to what the true propagated uncertainty should be, it is clearly a more complex calculation.  In the limited time available to complete your experiment and lab report, you may use the simpler, earlier uncertainty calculation method provided, and avoid this complicated calculation.  But do remember that the simpler method \emph{overestimates} the total uncertainty.

\section{Max-Min Method for Best-fit Line}

This alternate technique will show you how to draw an approximate best-fit line for a  set of data without a computer and it is sufficiently precise for most purposes.

First, try to draw a line with as many points (with uncertainties included) lying above the line as below it. The gauge of how close the line is to a point is given by the uncertainty associated with that measured point. However, all the points at the left end should not lie on one side of the line with all the points at the right end lying on the other side. As a rule of thumb, roughly 2/3 of the points should have the line passing through the uncertainties (just as with the 2/3 rule).\myskip
%The uncertainty for the best-fit line is obtained by estimating how much one could increase and decrease the slope of the line before the fit is deemed very bad. \myskip

Clearly, this ``eyeball'' method has inherent uncertainty, so how do we estimate the uncertainty on the slope of the best-fit line? To do this we should estimate the spread of the slope, or maximum and minimum possible slopes that one can conceivably interpret from the graph. Half the difference between the minimum and maximum slopes is a good estimate of the slope uncertainty ($\sigma=\frac{m_{max}-m_{min}}{2}$).
\end{document}
